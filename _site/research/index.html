<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  


























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Research | Stanford Trustworthy AI Research</title>

<link rel="icon" href="/images/icon.png">

<meta name="title" content="Research">
<meta name="description" content="STAIR">

<meta property="og:title" content="Research">
<meta property="og:site_title" content="Stanford Trustworthy AI Research">
<meta property="og:description" content="STAIR">
<meta property="og:url" content="">
<meta property="og:image" content="/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Research">
<meta property="twitter:description" content="STAIR">
<meta property="twitter:url" content="">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/images/share.jpg">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "Research",
    "description": "STAIR",
    "headline": "Research",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/images/icon.png" }
    },
    "url": ""
  }
</script>

<link rel="alternate" type="application/rss+xml" href="http://localhost:4000/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.3.0/css/all.css" rel="preload" as="style" onload="this.onload = null; this.rel = 'stylesheet';">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.3.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/_styles/all.css" rel="stylesheet">
  

  
    <link href="/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/_styles/background.css" rel="stylesheet">
  

  
    <link href="/_styles/body.css" rel="stylesheet">
  

  
    <link href="/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/_styles/button.css" rel="stylesheet">
  

  
    <link href="/_styles/card.css" rel="stylesheet">
  

  
    <link href="/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/_styles/code.css" rel="stylesheet">
  

  
    <link href="/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/_styles/float.css" rel="stylesheet">
  

  
    <link href="/_styles/font.css" rel="stylesheet">
  

  
    <link href="/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/_styles/form.css" rel="stylesheet">
  

  
    <link href="/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/_styles/header.css" rel="stylesheet">
  

  
    <link href="/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/_styles/image.css" rel="stylesheet">
  

  
    <link href="/_styles/link.css" rel="stylesheet">
  

  
    <link href="/_styles/list.css" rel="stylesheet">
  

  
    <link href="/_styles/main.css" rel="stylesheet">
  

  
    <link href="/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/_styles/section.css" rel="stylesheet">
  

  
    <link href="/_styles/table.css" rel="stylesheet">
  

  
    <link href="/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/_scripts/anchors.js"></script>

  <script src="/_scripts/dark-mode.js"></script>

  <script src="/_scripts/fetch-tags.js"></script>

  <script src="/_scripts/search.js"></script>

  <script src="/_scripts/site-search.js"></script>

  <script src="/_scripts/tooltip.js"></script>


</head>

  <body>
    







<header class="background" style="--image: url('/images/background.jpg')" data-dark="true">
  <a href="/" class="home">
    
      <span class="logo">
        
          <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns="http://www.w3.org/2000/svg" height="248.02pt" width="162pt" version="1.1" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" viewbox="0 0 162 248.022">
 <g>
  <path fill="#8c1515" d="m35.872 1.1236-34.558 33.832v90.907l30.041 30.665h13.776c-0.33541 0.92261-0.77516 2.3452 0.18119 3.7375 1.0401 1.5433 2.835 1.5433 3.5228 1.5433 0.80522 0 1.9291-0.10059 3.6571-0.33551h0.02027s0.72132 0.64079-1.4762 1.3621c-1.8117 0.63746-3.3919 1.6909-3.912 3.5025-0.03436 0.13399-0.04703 0.27196-0.08053 0.38918h-45.716l-0.013433 46.465 34.558 33.953h90.887l34.558-33.905v-87.077l-30.047-30.618h-25.478c-0.0172 0-0.0403-0.0134-0.0403-0.0134-1.1239-0.67099-2.2781-1.3789-3.3349-2.0667l-0.38917-0.24828-0.0671-0.04026c-0.57036-0.35214-1.1709-0.78508-1.8251-1.3554-0.57036-0.45294-1.0434-0.90584-1.3957-1.3085l-0.10066-0.10066c-0.67099-0.70459-1.2581-1.3789-1.7111-1.966 3.9756 1.1407 8.3071 1.4292 10.387 1.4963h0.24828c0.13399 0 0.27196 0.02027 0.38918 0.02027l0.18116 0.0134c0.50323 0.03436 0.88907 0.11712 1.1407 0.20129 0.26842 0.10049 0.5066 0.22159 0.72469 0.32208l1.0736 0.40261c0.25165 0.06699 0.52 0.08053 0.80522 0.08053 1.5601 0 3.0195-0.93941 3.6904-2.4156 0.21816-0.50327 0.5536-1.5064 0.30195-2.8316l45.442 0.03367v-50.76l-34.551-33.886h-90.887z"></path>
  <path fill="#fff" d="m157.19 36.804-32.1-31.487h-87.55l-32.108 31.436v87.382l27.628 28.182 17.815 0.0172c-1.9963 1.7949-2.6169 3.6569-2.9357 4.5628-0.68775 1.9962-1.4091 2.5665 4.8479 1.6943 1.9795-0.28515 5.5862-1.5601 7.2803-2.7008 1.6607-1.1407 4.9484-0.21816 4.6633 2.2479-1.5433 3.7743-5.502 6.1397-9.2768 6.6095-8.6893 1.0904-4.9317 4.3279-4.9317 4.3279 0.95619 0.65426 1.644 1.2917 2.1305 1.8621h-4.2273v-0.0172h-42.978l-0.017178 40.478 32.091 31.537h87.567l32.09-31.487v-83.539l-27.628-28.148h-22.327c-1.7781-1.1911-4.177-2.5163-6.3578-3.9421 0-0.01718 0-0.01718-0.0172-0.01718-0.83874-0.48647-1.6607-1.0903-2.4491-1.7781-0.65421-0.52001-1.2413-1.0736-1.7446-1.6272-1.9291-2.013-3.3717-4.1099-3.7576-5.0829-0.72133-1.7781-0.55355-4.026 1.0736-3.1034 4.1267 2.3821 10.904 2.835 13.42 2.9189 0.28515 0 2.3149 0.2349 2.8014 0.38564 0.50322 0.20141 1.2749 0.57034 1.2749 0.57034 1.0233 0.43614 2.8685-0.97294 0.73812-3.5731-0.55359-0.88907-1.3923-1.9124-2.3821-2.9524h47.354v-44.756"></path>
  <path d="m48.988 11.889l-37.05 36.297v104.79l31.537 32.17h29.607c5.053-2.22 6.123-2.03 7.527-4.86 0.21-0.45 0.418-1.75 0.44-3.02 0.063-0.36 0.693-4.18-1.153-3.25-3.166 1.59-9.562-2.61-14.343-0.11-4.781 2.47-1.279-3.27-0.608-4.26 0 0 2.558-3.37 6.416-5.6 0.147-0.08 0.273-0.16 0.377-0.25 0.378-0.21 0.756-0.39 1.155-0.58 2.935-1.37 11.3-6.94 12.81-8.68 0.902-1.01 2.496-3.32 2.559-4.6 0.272-1.11 0.483-2.87-0.586-3.56-1.594-1.05-2.874 1-5.369 2.12-2.496 1.11-4.383 1.57-6.606 1.65-2.138 0.07-4.193-0.75-5.472-0.56-1.28 0.21-2.035-0.76 0.314-3.13 1.069-1.07 1.532-1.55 2.035-1.91 5.578-3.58 10.589-3.62 13.399-9.98 0 0 2.181-5.7-2.034-3.27-2.306 1.34-3.564 3.27-10.17 3.27-6.584 0-9.164 3.13-10.275 4.49 0 0-4.486 6.27-3.375-2.52 1.133-8.76 2.83-13.23 6.961-16.65 3.564-2.93 12.412-6.87 15.6-11.21 1.635-1.62 5.746-6.32 3.355-10.299-1.007-1.678-3.459 2.669-5.996 3.229-2.894 0.76-6.563 1.7-9.373 1.13-3.481-0.69-5.704 0.63-7.004 1.22s-3.754-1.28-0.756-4.698c4.026-4.592 13.757-10.588 20.299-14.174 0.902-0.378 3.102-1.342 5.115-2.621 0.042-0.022 0.084-0.043 0.106-0.043 0.503-0.231 1.237-0.672 1.656-1.238 1.426-1.196 2.412-2.536 2.076-3.899-0.293-1.237-0.903-1.657-2.832-1.867-1.53-0.147-4.066 1.636-6.205 1.469-3.271-0.273-8.074 0.481-6.48-1.846 1.488-2.16 3.899-3.545 4.591-3.922 1.342-0.608 3.146-1.404 5.809-2.6 4.173-1.887 3.585-6.625 1.971-6.792-2.517-0.273-9.31 1.906-4.53-3.545 0 0 2.266-2.285 4.551-3.774 1.803-1.048 3.292-1.447 5.074-2.098 1.112-0.398 4.028-2.977-2.892-3.25 0 0-3.859 0.105-3.125-1.677 0.608-1.174 4.006-3.313 4.006-3.313s2.724-1.867 3.836-2.978c1.069-1.028 1.824-1.845 1.761-2.768-0.042-1.048-2.768-2.348-3.922-3.816-0.817-1.049-0.125-1.425 0.336-1.551 0.252-0.041 0.546-0.084 0.903-0.084 2.809 0.021 3.606-2.789 5.246-10.086 0.48-2.181 0.52-2.641 1.23-2.662 0.07 0 0.11 0.021 0.15 0.021 0 0 0.69 3.69 1.7 7.821 0.86 2.285 1.8 3.25 3.46 3.228 0.33 0 0.63 0.041 0.88 0.084 0.46 0.126 1.17 0.505 0.33 1.553-0.63 0.818-2.51 2.139-2.66 2.936-0.54 2.264 1.62 3.082 3.82 3.25 3.12 0.209 1.82 2.159-1.55 4.654-3.25 2.411 5.07 7.57 5.07 7.57 4.74 3.67 1.36 4.612 0.4 5.137-0.97 0.503-3.63 2.139-0.97 3.187 2.69 1.028 6.38 4.739 6.38 4.739 4.76 5.451-2.02 3.293-4.53 3.545-1.62 0.167-2.2 4.926 1.97 6.793 6.35 2.872 7.76 3.355 10 5.033 4.19 3.103 1.97 5.745-3.27 4.822 0 0-3.35-0.838-5.7-0.377-1.47 0.273-2.48 0.608-3.17 0.965-0.36 0.545-1.19 2.704 6.1 4.947 3.48 1.09 7.8 3.713 11.64 6.711l59.81-0.062-0.01-48.457-37.05-36.338h-105.3zm90.312 118.05c1.72 2.85 2.72 6.58 3.46 12.06 0.02 3.29-4.32 1.69-5.73 0.83-0.98-0.67-2.28-1.29-3.96-1.69-3.17-0.76-10.71-4.07-12.77-4.81-2.1-0.77-3.63 0.78-3.88 1.37h0.02c-0.54 1 0.57 3.02 0.57 3.02 2.96 6.71 8.41 6.35 14.4 10.65 8.24 5.87 3.84 7.11 2.14 6.23-1.67-0.9-4.44-0.34-4.44-0.34-6.65 1.83-8.64-0.94-12.54-1.97-3.88-1.05-0.69 3.78 0.71 5.39 1.49 1.74 9.88 7.32 12.79 8.68 6.36 2.96 9.67 7.76 11.64 13.86 1.87 5.77-0.17 4.51-1.68 3.8-1.51-0.72-1.95-2.27-5.7-2.18-3.77 0.08-5.89-0.19-8.58-2.31-0.71-0.55-1.28-1.18-1.76-1.7-0.04-0.02-0.06-0.04-0.08-0.06-2.58-1.97-2.08 4.57-1.55 5.64 1.86 3.75 3.12 2.22 13.86 7.95 5.09 2.72 6.29 6.37 6.83 7.9 0.86 2.48 1.74 3.19-6.06 2.1-2.49-0.34-6.98-1.93-9.12-3.38-2.05-1.42-6.18-0.27-5.81 2.81 1.93 4.72 6.88 7.68 11.6 8.26 4.13 0.53 6 1.43 6.75 2.35 2.26 2.58-1.93 6.36-1.93 6.36-2.1 2.43 0.17 5.28 1.72 6.12 2.52 1.28 7.4 4.21 9.02 8.41 8.47 21.8 0.27 15.55-3.74 13.06-4.02-2.5-11.68-8.91-18.66-8.35-6.98 0.55-9.31 0.93-13.46-2.37-4.13-3.29-3.73 2.04-3.73 2.04v26.29c0.25 5.89 1.34 11.51 6.02 16.27 3.83 3.93 6.75 3.19 12.16 9.8 2.49 3.04 10.63 6.31 16.06 6.37l10.42 0.02 37.05-36.34v-100.04l-31.51-32.1h-20.53zm-127.34 88.97l-0.021 43.09 37.05 36.36h11.91c11.198-0.55 15.391-9.23 18.788-14.57 2.558-4.05 7.088-7.49 9.961-10.43 3.04-3.08 3.586-10.13 3.669-17.76v-15.93l0.022 0.16v-3.81h0.021v-2.54h0.002v-0.59-6.87c0-1.6-1.845-1.72-5.871 2.64-4.047 4.34-10.819 3.98-14.74 4.34-3.921 0.35-15.202 6.23-18.432 10.44-1.992 2.62-4.823 0.46-3.67-4.7h-0.042c0.545-2.32 1.551-5.45 3.166-9.58 2.222-5.76 10.568-9.14 10.568-9.14s0.86-0.38 1.615-1.11h-53.996z" transform="matrix(.80001 0 0 .80001 -.00065308 0)" fill="#8c1515"></path>
 </g>
</svg>

        
      </span>
    
    
      <span class="title" data-tooltip="Home">
        
          <span>Stanford Trustworthy AI Research</span>
        
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/research/" data-tooltip="Published works">
          Research
        </a>
      
    
      
        <a href="/team/" data-tooltip="About our team">
          Team
        </a>
      
    
      
        <a href="/papers/" data-tooltip="Google Scholar, DPLB, arXiv">
          Paper
        </a>
      
    
      
        <a href="/talk/" data-tooltip="Tutorials &amp; Talks">
          Talks
        </a>
      
    
      
        <a href="/prospective_students/" data-tooltip="Interested in working with me?">
          Prosepctive Students
        </a>
      
    
      
        <a href="/teaching/" data-tooltip="Curent classes">
          Teaching
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - wrap each table in div to allow for scrolling
  - filter out blank sections
-->








  
  
  

  <section class="background" data-size="page">
    <h1 id="research">
<i class="icon fa-solid fa-microscope"></i>Research</h1>

<p>Our research interests are in developing the principles and practice of trustworthy machine learning. Some recent highlights include (i) robust federated machine learning, and (ii) metric elicitation; selecting more effective machine learning metrics via human interaction, primarily applied to ML fairness. Our applied research includes applications to cognitive neuroimaging, healthcare, and biomedical imaging. Some recent highlights include (i) generative models, and (ii) risk-scoring and prediction models for X-rays and fMRI.</p>

<h2 id="robust-distributed-and-federated-machine-learning">(Robust) Distributed and Federated Machine Learning</h2>

<p>Distributed data-centers and devices such as smart cars, smartphones, wearable devices, and smart sensors increasingly collect massive and diverse data. To this end, there is a growing interest in training machine learning models jointly across data centers without explicitly sharing data. Along similar lines, there is a trend towards on-device training of machine-learning models jointly across edge devices. However, despite some obvious benefits, distributed training and federated learning create new challenges for private and secure machine learning, as distributed devices are more susceptible to new privacy and security attacks. We are developing novel algorithmic and computational approaches to ensure the privacy and security of federated and distributed machine learning.</p>

<div class="alert" style="--color: #F59E0B">
  
  <div class="alert-content">
<p><strong>CSER: Communication-efficient SGD with Error Reset</strong><br>
Cong Xie, Shuai Zheng, Oluwasanmi Koyejo, Indranil Gupta, Mu Li, Haibin Lin<br>
Neural Information Processing Systems (NeurIPS), 2020<br>
<a href="https://arxiv.org/abs/2007.13221">[preprint]</a><br>
<strong>Zeno++: Robust Asynchronous SGD with an Arbitrary Number of Byzantine Workers</strong><br>
Cong Xie, Sanmi Koyejo, and Indranil Gupta<br>
International Conference on Machine Learning (ICML), 2020<br>
<a href="https://arxiv.org/abs/1903.07020">[preprint]</a><br>
[ML] <strong>Asynchronous Federated Optimization</strong><br>
Cong Xie, Sanmi Koyejo, and Indranil Gupta<br>
OPT 2020 workshop, NeurIPS 2020<br>
<a href="https://arxiv.org/abs/1903.03934">[preprint]</a><br>
<strong>Fall of empires: Breaking byzantine-tolerant SGD by inner product manipulation</strong><br>
Cong Xie, Sanmi Koyejo, and Indranil Gupta.<br>
Conference on Uncertainty in Artificial Intelligence (UAI), 2019<br>
<a href="https://arxiv.org/abs/1903.03936">[preprint]</a><br>
<strong>Practical distributed learning: Secure machine learning with communication-efficient local updates</strong><br>
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta.<br>
European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)<br>
<a href="https://arxiv.org/abs/1903.06996">[preprint]</a></p>
</div>
</div>

<h2 id="learning-with-complex-metrics">Learning with Complex Metrics</h2>

<p>Real-world machine learning often requires sophisticated evaluation metrics, many of which are non-decomposable, e.g., AUC, F-measure. This is in contrast to decomposable metrics such as accuracy, which can be computed as an empirical average. Indeed, non-decomposability is the primary source of difficulty in designing efficient algorithms that can optimize complex metrics. We study predictive methods from first principles and derive novel, efficient, statistically consistent algorithms that improve empirical performance.</p>

<div class="alert" style="--color: #F59E0B">
  
  <div class="alert-content">
<p><strong>Fairness with Overlapping Groups</strong><br>
Forest Yang, Moustapha Cisse, and Sanmi Koyejo<br>
Neural Information Processing Systems (NeurIPS), 2020<br>
<a href="https://arxiv.org/abs/2006.13485">[preprint]</a></p>

<p><strong>On the Consistency of Top-k Surrogate Losses</strong><br>
Forest Yang and Sanmi Koyejo<br>
<a href="https://arXiv.org/abs/1901.11141">[preprint]</a></p>

<p><strong>Binary Classification with Karmic, Threshold-Quasi-Concave Metrics</strong><br>
Bowei Yan, Oluwasanmi Koyejo, Kai Zhong and Pradeep Ravikumar.<br>
International Conference on Machine Learning (ICML), 2018<br>
<a href="http://proceedings.mlr.press/v80/yan18b.html">[url]</a></p>

<p><strong>Consistency Analysis for Binary Classification Revisited</strong><br>
Krzysztof Dembczynski, Wojciech Kotlowski, Oluwasanmi Koyejo, and Nagarajan Natarajan.<br>
International Conference on Machine Learning (ICML), 2017<br>
<a href="http://proceedings.mlr.press/v70/dembczynski17a.html">[url]</a></p>

<p><strong>Consistent binary classification with generalized performance metrics</strong><br>
Oluwasanmi Koyejo*, Nagarajan Natarajan*, Pradeep Ravikumar, and Inderjit Dhillon<br>
Advances in Neural Information Processing Systems (NIPS) 27, 2014 (Spotlight)<br>
<a href="http://papers.nips.cc/paper/5454-consistent-binary-classification-with-generalized-performance-metrics">[url]</a></p>
</div>
</div>

<h2 id="metric-elicitation">Metric Elicitation</h2>

<p>What metric (equiv. cost function, loss function) should a machine learning model optimize? Selecting a suitable metric for real-world machine learning applications remains an open problem, as default metrics such as classification accuracy often do not capture tradeoffs relevant to downstream decision-making. Unfortunately, there needs to be more formal guidance in the machine learning literature on selecting appropriate metrics. We are developing formal interactive strategies by which a practitioner may discover which metric to optimize, such that it recovers user or expert preferences. We are particularly interested in applications to ML fairness.</p>

<div class="alert" style="--color: #F59E0B">
  
  <div class="alert-content">
<p><strong>Quadratic Metric Elicitation with Application to Fairness</strong><br>
Gaurush Hiranandani, Jatin Mathur, Harikrishna Narasimhan and Oluwasanmi Koyejo<br>
Preprint, 2020<br>
<a href="https://arxiv.org/abs/2011.01516">[preprint]</a></p>

<p><strong>Fair Performance Metric Elicitation</strong><br>
Gaurush Hiranandani, Harikrishna Narasimhan, Oluwasanmi Koyejo<br>
Neural Information Processing Systems (NeurIPS), 2020<br>
<a href="https://arxiv.org/abs/2006.12732">[preprint]</a></p>

<p><strong>Multiclass Performance Metric Elicitation</strong><br>
Gaurush Hiranandani, Shant Boodaghians, Ruta Mehta, and Oluwasanmi Koyejo<br>
Neural Information Processing Systems (NeurIPS), 2019<br>
<a href="https://papers.nips.cc/paper/9133-multiclass-performance-metric-elicitation">[url]</a></p>

<p><strong>Performance metric elicitation from pairwise classifier comparisons</strong><br>
Gaurush Hiranandani, Shant Boodaghians, Ruta Mehta, and Oluwasanmi Koyejo<br>
International Conference on Artificial Intelligence and Statistics (AISTATS), 2019<br>
<a href="https://arXiv.org/abs/1806.01827">[preprint]</a></p>
</div>
</div>

<h2 id="probabilistic-graphical-models-for-spatio-temporal-data">Probabilistic Graphical Models for Spatio-temporal Data</h2>

<p>Spatio-temporal data are ubiquitous in science and engineering applications. We are pursuing various techniques for modeling such datasets, mainly using probabilistic graphical models and other graph-based analyses. We primarily use these tools to enable the scientific study and predictive modeling of brain networks. Of particular interest are novel methods that address robustness issues, e.g., confounding and novel distributed computation approaches.</p>

<div class="alert" style="--color: #F59E0B">
  
  <div class="alert-content">
<p><strong>Estimating Differential Latent Variable Graphical Models with Applications to Brain Connectivity</strong><br>
Sen Na, Mladen Kolar, and Oluwasanmi Koyejo.<br>
Biometrika, 2020<br>
<a href="https://arXiv.org/abs/1909.05892">[preprint]</a>
<a href="https://academic.oup.com/biomet/advance-article-abstract/doi/10.1093/biomet/asaa066/5901536">[url]</a><br>
<strong>Partially linear additive Gaussian graphical models</strong><br>
Sinong Geng, Minhao Yan, Mladen Kolar, and Sanmi Koyejo.<br>
International Conference on Machine Learning (ICML) pages 2180-2190, 2019<br>
<a href="http://proceedings.mlr.press/v97/geng19a.html">[url]</a><br>
<strong>Bayesian structure learning for dynamic brain connectivity</strong><br>
Michael Riis Andersen, Lars Kai Hansen, Ole Winther, Russell A. Poldrack, and Oluwasanmi Koyejo.<br>
International conference on Artificial Intelligence and Statistics (AISTATS), 2018<br>
<a href="http://proceedings.mlr.press/v84/andersen18a.html">[url]</a><br>
<strong>The Dynamics of Functional Brain Networks: Integrated Network States during Cognitive Task Performance</strong><br>
J.M. Shine, P.G. Bissett, P.T. Bell, O. Koyejo, J.H. Balsters, K.J. Gorgolewski, C.A. Moodie and R. A. Poldrack<br>
Neuron (2016)<br>
<a href="http://www.sciencedirect.com/science/article/pii/S0896627316305773">[url]</a>
<a href="http://arXiv.org/abs/1511.02976">[preprint]</a>
<a href="https://github.com/macshine/integration">[code]</a><br>
<strong>Temporal metastates are associated with differential patterns of time-resolved connectivity, network topology, and attention</strong><br>
James M. Shine, Oluwasanmi Koyejo, and Russell A. Poldrack<br>
Proceedings of the National Academy of Sciences (2016): 201604898.<br>
<a href="http://www.ncbi.nlm.nih.gov/pubmed/27528672">[url]</a>
<a href="http://arXiv.org/abs/1601.05065">[preprint]</a>
<a href="https://github.com/macshine/metaconnectivity">[code]</a></p>
</div>
</div>

<h2 id="generative-models-for-biological-images">Generative Models for Biological Images</h2>

<p>Data in scientific and commercial disciplines are increasingly characterized by high dimensions and relatively few samples. For such cases, apriori knowledge gleaned from experts and experimental evidence is invaluable for recovering meaningful models. Generative models are ideal for such knowledge-driven low-data settings. We are developing various generative models for biological imaging data and exploring novel applications of these models. We are also developing novel variational inference techniques that lead to the scalable and accurate inference, particularly for high-dimensional structured problems.</p>

<div class="alert" style="--color: #F59E0B">
  
  <div class="alert-content">
<p><strong>A generative modeling approach for interpreting population-level variability in brain structure</strong><br>
Ran Liu, Cem Subakan, Aishwarya H. Balwani, Jennifer D. Whitesell, Julie A. Harris, Sanmi Koyejo, and Eva Dyer<br>
International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2020<br>
<a href="https://www.biorxiv.org/content/10.1101/2020.06.04.134635v1">[preprint]</a></p>

<p><strong>Synthetic Power Analyses: Empirical Evaluation and Application to Cognitive Neuroimaging</strong><br>
Peiye Zhuang, Bliss Chapman, Ran Li, and Sanmi Koyejo<br>
Asilomar Conference on Signals, Systems, and Computers (Asilomar), 2019</p>

<p><strong>FMRI data augmentation via synthesis</strong><br>
Peiye Zhuang Alexander Schwing and Oluwasanmi Koyejo<br>
International Symposium on Biomedical Imaging (ISBI), 2019<br>
<a href="https://arxiv.org/abs/1907.06134">[preprint]</a></p>

<p><strong>Max-sliced wasserstein distance and its use for GANs</strong><br>
Ishan Deshpande, Yuan-Ting Hu, Ruoyu Sun, Ayis Pyrros, Sanmi Koyejo, Zhizhen Zhao, David Forsyth, and Alexander Schwing<br>
Conference on Computer Vision and Pattern Recognition (CVPR), 2019<br>
<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Deshpande_Max-Sliced_Wasserstein_Distance_and_Its_Use_for_GANs_CVPR_2019_paper.pdf">[PDF]</a></p>

<p><strong>On prior distributions and approximate inference for structured variables</strong><br>
Oluwasanmi Koyejo, Rajiv Khanna, Joydeep Ghosh, and Russell A Poldrack<br>
Advances in Neural Information Processing Systems (NIPS) 27, 2014<br>
<a href="http://papers.nips.cc/paper/5621-on-prior-distributions-and-approximate-inference-for-structured-variables">[url]</a></p>
</div>
</div>

<h2 id="learning-with-aggregated-data">Learning with Aggregated Data</h2>

<p>Existing work in spatiotemporal data analysis often assumes that data are available as individual measurements. However, for reasons of privacy or storage, data is usually only available as aggregates. Data aggregation presents severe mathematical challenges to learning and inference, and a naive application of standard techniques is susceptible to the ecological fallacy. We have shown that aggregation has only a mild effect on model estimates in some cases. We are developing various tools for other cases that enable provably accurate predictive modeling with aggregated data while avoiding unnecessary and error-prone data reconstruction.</p>

<div class="alert" style="--color: #F59E0B">
  
  <div class="alert-content">
<p><strong>Aggregation for Sensitive Data</strong><br>
Avradeep Bhowmik, Joydeep Ghosh, and Oluwasanmi Koyejo<br>
13th International conference on Sampling Theory and Applications (SampTA), 2019<br>
<a href="https://sampta2019.sciencesconf.org/267460/document">[url]</a></p>

<p><strong>Frequency Domain Predictive Modeling with Aggregated Data</strong><br>
Avradeep Bhowmik, Joydeep Ghosh, Oluwasanmi Koyejo<br>
Proceedings of the 20th International conference on Artificial Intelligence and Statistics (AISTATS), 2017<br>
<a href="http://proceedings.mlr.press/v54/bhowmik17a">[url]</a></p>

<p><strong>Sparse parameter recovery from aggregated data</strong><br>
Avradeep Bhowmik, Joydeep Ghosh, and Oluwasanmi Koyejo<br>
International Conference on Machine Learning (ICML), 2016<br>
<a href="http://www.jmlr.org/proceedings/papers/v48/bhowmik16.html">[url]</a></p>
</div>
</div>

<h2 id="interpretable-machine-learning">Interpretable Machine Learning</h2>

<p>As machine learning methods have become ubiquitous in human decision-making, their transparency and interpretability have become important. Interpretability is particularly important in domains where decisions can have significant consequences. Examples abound where interpretable models can reveal important but surprising patterns in the data that complex models obscure. We are currently studying exemplar-based interpretable modeling. This is motivated by studies of human reasoning, which suggest that using examples (prototypes) is fundamental to developing effective strategies for tactical decision-making. We are also exploring the application of structured sparsity and attention (with deep neural networks) to enable interpretability.</p>

<div class="alert" style="--color: #F59E0B">
  
  <div class="alert-content">
<p><strong>Interpreting black box predictions using Fisher kernels</strong><br>
Rajiv Khanna, Been Kim, Joydeep Ghosh, and Oluwasanmi Koyejo<br>
International Conference on Artificial Intelligence and Statistics (AISTATS), 2019<br>
<a href="https://arXiv.org/abs/1810.10118">[preprint]</a></p>

<p><strong>Examples are not Enough, Learn to Criticize! Criticism for Interpretable Machine Learning</strong><br>
Been Kim<em>, Rajiv Khanna</em> and Oluwasanmi Koyejo*<br>
Advances in Neural Information Processing Systems (NIPS) 29, 2016 (Oral)<br>
<a href="https://papers.nips.cc/paper/6300-examples-are-not-enough-learn-to-criticize-criticism-for-interpretability">[url]</a> <a href="https://github.com/BeenKim/MMD-critic">[code]</a></p>

<p><strong>Sparse dependent Bayesian structure learning</strong><br>
Anqi Wu, Mijung Park, Oluwasanmi Koyejo, and Jonathan Pillow<br>
Advances in Neural Information Processing Systems (NIPS) 27, 2014<br>
<a href="http://papers.nips.cc/paper/5233-sparse-bayesian-structure-learning-with-dependent-relevance-determination-priors">[url]</a></p>
</div>
</div>

<p><strong>Funding</strong>: We graciously acknowledge generous funding support from the <a href="https://www.nsf.gov/" target="\_blank">National Science Foundation</a>, <a href="https://www.nih.gov/" target="\_blank">National Institutes of Health</a>, <a href="https://ai.google/" target="\_blank">Google AI</a>, <a href="https://www.darpa.mil/" target="\_blank">DARPA</a>, <a href="https://jumpsimulation.org/research-innovation/research/jump-arches" target="\_blank">Jump ARCHES</a>, <a href="https://dpi.uillinois.edu/" target="\_blank">Discovery Partners Institute</a>, <a href="https://jumpsimulation.org/research-innovation/research/jump-arches" target="\_blank">Digital Transformation Institute</a>, <a href="https://ccbgm.illinois.edu/" target="\_blank">CCBGM</a>, <a href="https://www.omnilife.ai/" target="\_blank">Onmilife</a>, and the <a href="https://mayoillinois.org/" target="\_blank">Mayo Clinic &amp; Illinois Alliance</a>. Our research is also supported by generous computing support from <a href="https://azure.microsoft.com/en-us/" target="\_blank">Microsoft Azure</a>, <a href="https://www.intel.ai/" target="\_blank">Intel AI</a>, <a href="https://aws.amazon.com/" target="\_blank">Amazon Web Services</a>, <a href="https://cloud.google.com/" target="\_blank">Google Cloud</a>, and <a href="https://bluewaters.ncsa.illinois.edu/" target="\_blank">NCSA Bluewaters</a>. We have also received funding from the <a href="https://research.illinois.edu/olga-g-nalbandov-lecture-fund" target="\_blank">Olga G. Nalbandov Lecture Fund</a>, the <a href="https://www.macfound.org/" target="\_blank">MacArthur Foundation</a>, and the <a href="https://www.rockefellerfoundation.org/" target="\_blank">Rockefeller Foundation</a> to support our outreach efforts.</p>
  </section>


    </main>
    


<footer class="background" style="--image: url('/images/background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://github.com/koyejo-lab" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://twitter.com/stai_research" data-tooltip="Twitter" data-style="bare" aria-label="Twitter">
      <i class="icon fa-brands fa-twitter"></i>
      
    </a>
  </div>


    
  </div>

  <div>
    © 2024
    Stanford Trustworthy AI Research
       
    <a href="https://github.com/greenelab/lab-website-template">
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
